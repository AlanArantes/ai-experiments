{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AI: Building a Patient Priority Classification Using BERT and Transformers\n",
        "\n",
        "**Author**: Alan Arantes - Enterprise & System Architect  \n",
        "**Reading Time**: 6 min  \n",
        "\n",
        "## TL;DR\n",
        "A practical overview to implementing an automated medical triage system using BERT and the Transformers library, helping medical staff prioritize patients efficiently through deep learning.\n",
        "\n",
        "## Introduction\n",
        "In busy medical environments, quick and accurate patient prioritization can mean the difference between life and death. While experienced medical professionals excel at this task, automating the initial triage process can help streamline operations and ensure consistent evaluation.\n",
        "\n",
        "We'll use BERT (Bidirectional Encoder Representations from Transformers) to create a system that can understand and prioritize patient descriptions. The implementation uses PyTorch and the Transformers library from Hugging Face.\n",
        "\n",
        "## The Role of Self-Attention in Medical Triage\n",
        "BERT's self-attention mechanism can serve as a tool for accurate patient prioritization. It enables the model to process multiple aspects of a patient's condition simultaneously, similar to how a medical professional assesses a situation:\n",
        "\n",
        "1. **Symptom Relationships**: Self-attention weighs symptom combinations (e.g., \"chest pain\" with \"shortness of breath\" indicating higher urgency than either alone).\n",
        "2. **Contextual Understanding**: Words are interpreted in relation to each other, distinguishing between scenarios like \"severe acute pain\" and \"mild chronic pain\".\n",
        "3. **Demographic Consideration**: The attention mechanism connects patient demographics with symptoms, recognizing that similar symptoms might indicate different priorities based on age or history.\n",
        "\n",
        "This powerful mechanism processes inputs by computing attention scores that determine how different parts of a patient's description should influence each other, leading to more accurate priority predictions.\n",
        "\n",
        "### Self-Attention Process\n",
        "The self-attention process works by computing three vectors for each element in the input:\n",
        "- **Query (Q)**: What information the element is looking for\n",
        "- **Key (K)**: What information the element can provide\n",
        "- **Value (V)**: The actual content to be passed along\n",
        "\n",
        "This mechanism is particularly powerful for classification tasks because it allows the model to:\n",
        "- Identify and weigh crucial symptoms appropriately\n",
        "- Consider multiple factors simultaneously\n",
        "- Learn complex patterns in medical presentations\n",
        "- Adapt to various description formats and lengths\n",
        "\n",
        "## The Building Blocks: Understanding Each Component\n",
        "\n",
        "### Resources and Dependencies\n",
        "To run this code, you'll need:\n",
        "- Python 3.6+\n",
        "- PyTorch\n",
        "- Transformers library\n",
        "- CUDA-capable GPU (recommended)\n",
        "- Pandas and NumPy\n",
        "- Scikit-learn\n",
        "\n",
        "## Understanding the Essential Imports for BERT-based Patient Classification\n",
        "### Core Deep Learning Libraries\n",
        "\n",
        "***PyTorch Framework***"
      ],
      "metadata": {
        "id": "x1uzdgDIG23L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "xtMk6UkKJsVV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- torch: The main PyTorch library for deep learning operations\n",
        "- Dataset: Base class for creating custom datasets\n",
        "- DataLoader: Handles batch processing and data loading during training\n",
        "\n",
        "***Transformers Components***"
      ],
      "metadata": {
        "id": "6cIuyVL0Jt1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup"
      ],
      "metadata": {
        "id": "23VNVxMdJ7PQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **AutoTokenizer:** Handles text tokenization for BERT\n",
        "- **AutoModelForSequenceClassification:** Pre-trained BERT model adapted for classification\n",
        "- **AdamW:** Optimizer specialized for transformer models\n",
        "- **get_linear_schedule_with_warmup:** Learning rate scheduler for better training\n",
        "\n",
        "### Data Processing Libraries\n",
        "Scientific Computing"
      ],
      "metadata": {
        "id": "IhQkhKNUJ8AW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "FkW2P5uiKNVz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **numpy:** Essential for numerical operations and array manipulations\n",
        "\n",
        "### Machine Learning Tools"
      ],
      "metadata": {
        "id": "4kOabQKxKPXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "xkusx0quKUk8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **train_test_split:** Splits data into training and validation sets\n",
        "\n",
        "### Data Manipulation"
      ],
      "metadata": {
        "id": "4yg7ZtgnKVRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "TshL27SgKhdQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Key Points\n",
        "\n",
        "This combination of imports provides all necessary tools for:\n",
        "\n",
        "- Deep learning model implementation\n",
        "- Text processing\n",
        "- Data handling\n",
        "- Model training and evaluation\n",
        "\n",
        "The focus is on transformer-based architectures with proper data management support\n",
        "\n",
        "## 1. Custom Dataset Implementation+\n",
        "\n",
        "This custom dataset class is the foundation of our system. It inherits from PyTorch's Dataset class and handles:\n",
        "\n",
        "* Text tokenization for BERT processing\n",
        "* Label encoding for priority levels\n",
        "* Proper formatting of input data\n",
        "* Batch processing preparation\n",
        "\n",
        "The class converts raw patient descriptions into the tensor format required by BERT, handling all necessary padding and truncation automatically."
      ],
      "metadata": {
        "id": "syqwuH2HKivQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class PatientDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n"
      ],
      "metadata": {
        "id": "h7AI8fcFHKAB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training Architecture\n",
        "\n",
        "In below I'll break down each main section of the training function and explain exactly what it does:\n",
        "\n",
        "### Data Preparation and Model Setup Flow\n",
        "\n",
        "#### Sample Data Construction\n",
        "\n",
        "The journey begins with preparing our sample patient data, structured as clear medical descriptions. Each entry contains vital information like symptoms, gender, and age:"
      ],
      "metadata": {
        "id": "mxMpUptTLqg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patient_data = [\n",
        "    \"Severe chest pain, shortness of breath, male, age 65\",\n",
        "    \"Mild headache, female, age 25\",\n",
        "    \"High fever, cough, difficulty breathing, male, age 45\",\n",
        "]"
      ],
      "metadata": {
        "id": "8002HnSRNMpw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each patient description, we assign priority levels (0: low, 1: medium, 2: high) to train our model:"
      ],
      "metadata": {
        "id": "odbW_8CXNOR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [2, 0, 1]"
      ],
      "metadata": {
        "id": "APkvWvvkNRNM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT Model Initialization\n",
        "\n",
        "We then initialize our BERT model, using the 'bert-base-uncased' variant. This process involves two key components:\n"
      ],
      "metadata": {
        "id": "cGGRwk98NXFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=3\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsOOdr_pNXug",
        "outputId": "e27ab1c8-1885-4de3-ea80-9d62ca810b4b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tokenizer will process our text inputs, while the model is configured for three-level classification (low, medium, high priority).\n",
        "\n",
        "## Data Organization\n",
        "\n",
        "The data is split into training and validation sets using scikit-learn's train_test_split, with 20% reserved for validation:"
      ],
      "metadata": {
        "id": "RjrW2mwWNhK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    patient_data, labels, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "Il4aHQYTNiof"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These splits are then transformed into PyTorch datasets:"
      ],
      "metadata": {
        "id": "HWKGJLr6NkXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = PatientDataset(X_train, y_train, tokenizer)\n",
        "val_dataset = PatientDataset(X_val, y_val, tokenizer)"
      ],
      "metadata": {
        "id": "eDrJWIINNmDo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Setup\n",
        "\n",
        "DataLoaders are created to handle batching and shuffling during training:"
      ],
      "metadata": {
        "id": "DQlazsEpNpLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32)"
      ],
      "metadata": {
        "id": "ew7Mzl4dNrF_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we ensure our model can utilize available GPU acceleration if present:"
      ],
      "metadata": {
        "id": "pKQjqvG6NtV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnAFflxmNvjf",
        "outputId": "e04ad605-2d3b-44ad-d68b-5bbba5ed6df8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This setup creates a complete pipeline from raw patient descriptions to a model ready for training on the appropriate hardware.\n",
        "\n",
        "# Training Process Breakdown\n",
        "\n",
        "## Optimization Setup\n",
        "\n",
        "We begin by configuring the training environment with the AdamW optimizer, specifically designed for transformer models. The learning rate is carefully set to 2e-5, a value known to work well with BERT fine-tuning:"
      ],
      "metadata": {
        "id": "pbb5i7WlNygF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpGfqJkuObhk",
        "outputId": "b4552bb0-9605-440f-aea7-8c03376dcc41"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop\n",
        "\n",
        "The training process unfolds across multiple epochs, where each epoch represents a complete pass through the dataset. Within each epoch:"
      ],
      "metadata": {
        "id": "1TwyIG-tOo1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "        print(f'Epoch {epoch + 1}/{epochs}')\n",
        "\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "\n",
        "### Batch Processing\n",
        "#### Each batch undergoes a series of transformations and computations:\n",
        "        for batch in train_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "### The model processes these inputs to generate predictions and calculate losses:\n",
        "            model.zero_grad()\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "            )\n",
        "\n",
        "### Optimization Step\n",
        "#### The backpropagation and optimization process occurs after each batch:\n",
        "            loss = outputs.loss\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "        print(f'Average training loss: {avg_train_loss}')\n",
        "\n",
        "## Validation Phase\n",
        "#### After training, the model enters evaluation mode to assess its performance on unseen data:\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        predictions = []\n",
        "        true_labels = []\n",
        "\n",
        "        for batch in val_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "### Validation Processing\n",
        "#### During validation, we process batches without computing gradients:\n",
        "            with torch.no_grad():\n",
        "                outputs = model(\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    labels=labels\n",
        "                )\n",
        "\n",
        "            loss = outputs.loss\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "            predictions.extend(outputs.logits.argmax(dim=1).cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "### Performance Metrics\n",
        "#### Finally, we calculate and display key performance metrics:\n",
        "        avg_val_loss = total_val_loss / len(val_dataloader)\n",
        "        accuracy = np.mean(np.array(predictions) == np.array(true_labels))\n",
        "        print(f'Average validation loss: {avg_val_loss}')\n",
        "        print(f'Validation accuracy: {accuracy}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oef0ENGZOprs",
        "outputId": "0feabe5d-3fd8-4679-fba7-d639cae84369"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "Average training loss: 1.8512301445007324\n",
            "Average validation loss: 0.6676399111747742\n",
            "Validation accuracy: 1.0\n",
            "Epoch 2/3\n",
            "Average training loss: 1.2944049835205078\n",
            "Average validation loss: 0.8853601813316345\n",
            "Validation accuracy: 1.0\n",
            "Epoch 3/3\n",
            "Average training loss: 1.3907421827316284\n",
            "Average validation loss: 1.1244556903839111\n",
            "Validation accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Real-World Application Finally\n",
        "The trained model is put to practical use. New patient cases are processed:"
      ],
      "metadata": {
        "id": "-Qenj_3EREUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of prioritizing new patients\n",
        "new_patients = [\n",
        "    \"Severe abdominal pain, vomiting, female, age 35\",\n",
        "    \"Minor cuts and bruises, male, age 28\",\n",
        "]"
      ],
      "metadata": {
        "id": "qFUmlZD1RL4i"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding the Priority Prediction Function\n",
        "\n",
        "## Function Overview\n",
        "\n",
        "The `predict_priority` function serves as our prediction pipeline, taking a trained model and new patient data to determine medical priority levels. Let's break down its implementation:\n",
        "\n",
        "## Data Preparation\n",
        "\n",
        "First, we prepare our data for prediction by creating a dataset instance:"
      ],
      "metadata": {
        "id": "I-cbQZiwRekP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "dataset = PatientDataset(patient_data, [0]*len(patient_data), tokenizer)\n",
        "dataloader = DataLoader(dataset, batch_size=32)\n",
        "priorities = []\n"
      ],
      "metadata": {
        "id": "8Y-yVt_iRhRj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function creates temporary labels (zeros) since we only need the text processing capability of our dataset class, not actual labels.\n",
        "\n",
        "## Prediction Process\n",
        "\n",
        "The core prediction happens within a no-gradient context, ensuring efficiency:"
      ],
      "metadata": {
        "id": "WKs7nfuBR1oe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  for batch in dataloader:\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "### Model Inference\n",
        "#### The model processes each batch and generates probability distributions for priority levels:\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    priorities.extend(outputs.logits.softmax(dim=1).cpu().numpy())"
      ],
      "metadata": {
        "id": "gn2MGl2KR55q"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we use softmax to convert model outputs into probability distributions, making our predictions more interpretable. The results are moved to CPU and converted to numpy arrays for easier post-processing.\n",
        "\n",
        "The function efficiently processes multiple patients in batches and returns their priority predictions, making it suitable for real-time applications in a medical setting.\n",
        "\n",
        "# Results Processing and Display\n",
        "\n",
        "## Priority List Creation\n",
        "\n",
        "The final stage of our medical triage system involves organizing and presenting the predictions in a meaningful way:\n"
      ],
      "metadata": {
        "id": "mtDQ0S1iSWgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "priority_list = [\n",
        "    (patient, priority)\n",
        "    for patient, priority in zip(new_patients, priorities)\n",
        "]\n"
      ],
      "metadata": {
        "id": "WcQdgteBSwM5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This creates paired tuples of patients and their predicted priority scores, combining our input data with model predictions.\n",
        "\n",
        "## Priority Sorting\n",
        "\n",
        "The patients are then sorted by priority level, ensuring urgent cases appear first:"
      ],
      "metadata": {
        "id": "HFKDSmMiS8ES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "priority_list.sort(key=lambda x: x[1].max(), reverse=True)"
      ],
      "metadata": {
        "id": "wnIeelyFS9UE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sorting uses the highest probability score for each patient, with `reverse=True` ensuring a highest-to-lowest ordering.\n",
        "\n",
        "## Results Presentation\n",
        "\n",
        "Finally, we present the results in a clear, human-readable format:\n"
      ],
      "metadata": {
        "id": "VYdxtZy-TB87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPatient Priority List:\")\n",
        "for patient, priority in priority_list:\n",
        "    priority_level = [\"Low\", \"Medium\", \"High\"][priority.argmax()]\n",
        "    print(f\"Patient: {patient}\")\n",
        "    print(f\"Priority Level: {priority_level}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQYuQGcqTEVR",
        "outputId": "612215ce-b31b-4b47-957b-fd6d2bb69544"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Patient Priority List:\n",
            "Patient: Minor cuts and bruises, male, age 28\n",
            "Priority Level: Low\n",
            "\n",
            "Patient: Severe abdominal pain, vomiting, female, age 35\n",
            "Priority Level: Low\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The predictions are converted from numerical values to meaningful labels (\"Low\", \"Medium\", \"High\") using the `argmax()` function to select the most likely priority level. This creates a straightforward report that medical staff can quickly understand and act upon.\n",
        "\n",
        "This creates a sorted list of patients based on their priority levels, from most urgent to least urgent. The output format makes it easy for medical staff to quickly identify which patients need immediate attention.\n",
        "\n",
        "The entire process flows from data preparation through model training to practical application, creating a complete pipeline for medical triage automation.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "This implementation demonstrates how modern NLP techniques can be applied to real-world healthcare challenges. The system provides:\n",
        "\n",
        "* Automated initial triage assessment\n",
        "* Consistent patient prioritization\n",
        "* Scalable processing of patient descriptions\n",
        "* Real-time priority predictions\n",
        "\n",
        "While this system serves as a valuable tool for medical staff, it's important to note that it should be used as a support system rather than a replacement for professional medical judgment.\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "To further implement within a system, consider:\n",
        "\n",
        "1. Incorporating additional patient metadata\n",
        "2. Implementing multi-lingual support\n",
        "3. Adding explainability features\n",
        "4. Developing a user interface for medical staff\n",
        "5. Expanding the priority levels for finer-grained triage"
      ],
      "metadata": {
        "id": "w2s7FXzfTGDz"
      }
    }
  ]
}